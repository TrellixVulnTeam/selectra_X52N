{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33d077-95b4-4015-b58c-e7cfe6c27f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoModelForSequenceClassification, ElectraTokenizerFast\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import set_seed\n",
    "from pathlib import Path\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8321901-19b8-47eb-90d0-9a8e20a4dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnli_es = datasets.load_dataset(\"xnli\", \"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87bcb1-a538-448d-a38e-ff3c2b1192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >joeddav\n",
    "# >Aug '20\n",
    "# >\n",
    "# >@rsk97 In addition, just make sure the model used is trained on an NLI task and that the **last output label corresponds to entailment** while the **first output label corresponds to contradiction**.\n",
    "#\n",
    "# => We change the original `label` and use the `labels` column, which is required by a `AutoModelForSequenceClassification`\n",
    "def switch_label_id(row):\n",
    "    if row[\"label\"] == 0:\n",
    "        return {\"labels\": 2}\n",
    "    elif row[\"label\"] == 2:\n",
    "        return {\"labels\": 0}\n",
    "    else:\n",
    "        return {\"labels\": 1}\n",
    "\n",
    "for split in xnli_es:\n",
    "    xnli_es[split] = xnli_es[split].map(switch_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da79fc-c2cd-422f-8b17-c3627cafd44d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep in mind that the accented tokens were not optimized in our pretrained language model\n",
    "# -> strip_accents=False means that we optimize them from scratch during the fine-tuning \n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(\"Recognai/selectra_small\", strip_accents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519bb2c-a145-4e22-aad1-51ba5cc9fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    return tokenizer(row[\"premise\"], row[\"hypothesis\"], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23992c-b6eb-4e98-93c2-e84932af56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for split in xnli_es:\n",
    "    data[split] = xnli_es[split].map(\n",
    "        tokenize, \n",
    "        remove_columns=[\"hypothesis\", \"premise\", \"label\"], \n",
    "        batched=True, \n",
    "        batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34165f52-1b06-449b-bf9e-f2bee83420d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = datasets.load_metric(\"xnli\", \"es\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2404f51-bc58-47bb-8caa-0b7cc0f81ff4",
   "metadata": {},
   "source": [
    "# Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144be610-457b-4607-9192-3ff067fd7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we performed a random seed sweep and settled on 2\n",
    "set_seed(2)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Recognai/selectra_small\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d417e92-9859-4614-b655-f623dca919ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c145e-741b-4b1f-b433-304aad5666e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_small_seed2CasedUnstripped',          # output directory\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",  # \"steps\",\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    learning_rate=1e-4,\n",
    "    adam_epsilon=1e-6,\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=250,\n",
    "    save_steps=500,  # ignored when using load_best_model_at_end\n",
    "    save_total_limit=10,\n",
    "    #no_cuda=False,\n",
    "    #disable_tqdm=True,\n",
    "    seed=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e599d9-6ab8-461d-a1f6-c5ab1e994bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=data[\"train\"],         # training dataset\n",
    "    eval_dataset=data[\"validation\"],          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb8f17-2606-41ca-b058-98b4437513eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40bddc5-ec56-4bb1-969e-3b4d41134898",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls results_small_seed2CasedUnstripped/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d7636-e7ea-4b87-adb7-9ca5ce1c0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"results_small_seed2CasedUnstripped/checkpoint-45000\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ed09a-bb43-4a46-8dff-b9357e49b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_small',          # output directory\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",  # \"steps\",\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    learning_rate=1e-4,\n",
    "    adam_epsilon=1e-6,\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=250,\n",
    "    save_steps=500,  # ignored when using load_best_model_at_end\n",
    "    save_total_limit=10,\n",
    "    #no_cuda=False,\n",
    "    #disable_tqdm=True,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d2668-5817-4d93-9126-4e8d75230146",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=data[\"train\"],         # training dataset\n",
    "    eval_dataset=data[\"validation\"],          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59633bf6-5f1f-4232-a78d-7eca2f6db6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53a4df9-299a-4bf9-a9dc-05359580b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r results_small_seed2CasedUnstripped/checkpoint-45000 small_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a923ac-b562-4ef6-991d-93d905313154",
   "metadata": {},
   "source": [
    "# Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d986c-c50b-4c98-937e-b8a4779214c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we performed a random seed sweep and settled on 2\n",
    "set_seed(2)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Recognai/selectra_medium\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437768d-c87a-47ee-9a44-18300e93d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a4faf-3612-4e32-b616-d489c0d70f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_medium_seed2CasedUnstripped',          # output directory\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",  # \"steps\",\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    learning_rate=1e-4,\n",
    "    adam_epsilon=1e-6,\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=250,\n",
    "    save_steps=500,  # ignored when using load_best_model_at_end\n",
    "    save_total_limit=10,\n",
    "    #no_cuda=False,\n",
    "    #disable_tqdm=True,\n",
    "    seed=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2058800-8c9f-4d2e-8cf1-4e7a06d5461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=data[\"train\"],         # training dataset\n",
    "    eval_dataset=data[\"validation\"],          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062d9bd-a911-4695-8883-88e306244db8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04134107-43d0-4f97-a176-bdc7b794585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls results_medium_seed2CasedUnstripped/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b22f2-0ab2-4162-979e-fc18c12b8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"results_medium_seed2CasedUnstripped/checkpoint-23500\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fecafb-2e1b-4882-8f53-3454165a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_medium',          # output directory\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",  # \"steps\",\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_ratio=0.1,\n",
    "    #warmup_steps=len(data[\"train\"]) // 32 * 5,  # 500\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    learning_rate=1e-4,\n",
    "    adam_epsilon=1e-6,\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=250,\n",
    "    save_steps=500,  # ignored when using load_best_model_at_end\n",
    "    save_total_limit=10,\n",
    "    #no_cuda=False,\n",
    "    #disable_tqdm=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "#training_args.report_to = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f8c1f-727a-4861-8f38-db5112b9fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=data[\"train\"],         # training dataset\n",
    "    eval_dataset=data[\"validation\"],          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181251a3-99b8-400b-9584-2c9d23b26343",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073ecdf-53a9-4b0f-9eb2-30defe566dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp results_medium_seed2CasedUnstripped/checkpoint-23500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cf2eb-e126-4f03-9942-81b0b4b1d0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
